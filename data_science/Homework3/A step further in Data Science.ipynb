{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"ITU-Lahore-Logo.jpeg\">\n",
    "<h1><center>Data Science Lab</center>\n",
    "<center>Information Technology University, Punjab</center>\n",
    "<center>Homework 3</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-**\n",
    "<h3>Instructions:</h3>\n",
    "* The aim of homework is to give you understanding of comlete Data Science pipeline. \n",
    "* You need to submit a detailed notebook with suitable headings and comments. You would not be graded if you submit an erroneous notebook.\n",
    "* **Please complete this assignment and submit the complete folder with it's name as your registration number i.e. \"MSDS18###.zip\" on Google Classroom.**\n",
    "* <font color='red'>This is a well drafted assignment, I hope that there would be no need for you to look for solutions on internet. Simply follow the instructions and you would be good to go.</font>\n",
    "**-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study Continued"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Titanic: Machine Learning From Disaster</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"files/titanic ship.jpg\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n",
    "\n",
    "One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n",
    "\n",
    "In this challenge, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has been split into two groups:\n",
    "\n",
    "* training set (train.csv)\n",
    "* test set (test.csv)\n",
    "\n",
    "The **training set** should be used to build your machine learning models. For the training set, we provide the outcome (also known as the “ground truth”) for each passenger. Your model will be based on “features” like passengers’ gender and class. You can also use <font color = \"blue\">feature engineering</font> to create new features.\n",
    "\n",
    "The **test set** should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|<h3>**Variable**</h3>|<h3>**Definition**</h3>|<h3>**Key**</h3>|\n",
    "|:-|:-|:-|\n",
    "|PassengerId|Unique Identifier of each passenger||\n",
    "|Survived|Survival|0 = No, 1 = Yes|\n",
    "|Pclass|Ticket class|1 = 1st, 2 = 2nd, 3 = 3rd|\n",
    "|Name|Name of Passenger||\n",
    "|Sex|Gender||\n",
    "|Age|Age in years||\n",
    "|SibSp|# of siblings / spouses aboard the Titanic||\n",
    "|Parch|# of parents / children aboard the Titanic||\n",
    "|Ticket|Ticket number||\n",
    "|Fare|Passenger fare||\n",
    "|Cabin|Cabin number||\n",
    "|Embarked|Port of Embarkation|C = Cherbourg, Q = Queenstown, S = Southampton|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Detail of some of the variables is provided. You need to explore rest of the varibles yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop Irrelevant Attributes\n",
    "\n",
    "In your initial analysis, you must have noticed that there were some attributes that did not play any role in prediction. Therefore, we would remove these attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.drop(['PassengerId', 'Ticket' ], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Current Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass                                               Name  \\\n",
       "0         0       3                            Braund, Mr. Owen Harris   \n",
       "1         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2         1       3                             Heikkinen, Miss. Laina   \n",
       "3         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4         0       3                           Allen, Mr. William Henry   \n",
       "\n",
       "      Sex   Age  SibSp  Parch     Fare Cabin Embarked  \n",
       "0    male  22.0      1      0   7.2500   NaN        S  \n",
       "1  female  38.0      1      0  71.2833   C85        C  \n",
       "2  female  26.0      0      0   7.9250   NaN        S  \n",
       "3  female  35.0      1      0  53.1000  C123        S  \n",
       "4    male  35.0      0      0   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just said before that we would remove all irrelevant attributes.<br>\n",
    "* **Are 'Name' and 'Cabin' not irrelevant attribute? Take a minute and think about it.**\n",
    "<img src = \"files/ConfusedEmoji.jpg\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "Yes 'Name' and 'Cabin' seems to be irrelevant but we are not going to remove them yet. There is no need to be confused or surprised, as we are going to introduce a new concept called <font color='blue'>Feature Engineering.</font>\n",
    "\n",
    "**Feature engineering** is the process of transforming raw data into features that better represent the underlying problem to the predictive models, resulting in improved model accuracy on unseen data.\n",
    "\n",
    "**What do experts say about Feature Engineering?**\n",
    "\n",
    "* *feature engineering is another topic which doesn’t seem to merit any review papers or books, or even chapters in books, but it is absolutely vital to ML success. […] Much of the success of machine learning is actually success in engineering features that a learner can understand.* \n",
    "\n",
    "— Scott Locklin, in “Neglected machine learning ideas”\n",
    "\n",
    "* *Actually the success of all Machine Learning algorithms depends on how you present the data.*\n",
    "\n",
    "— Mohammad Pezeshki, answer to “What are some general tips on feature selection and engineering that every data scientist should know?”\n",
    "\n",
    "* *The algorithms we used are very standard for Kagglers. […]  We spent most of our efforts in feature engineering.*\n",
    "\n",
    "— Xavier Conort, on “Q&A with Xavier Conort” on winning the Flight Quest challenge on Kaggle\n",
    "\n",
    "* *“At the end of the day, some machine learning projects succeed and some fail. What makes the difference? Easily the most important factor is the features used.”*\n",
    "\n",
    "— Prof. Pedro Domingos\n",
    "\n",
    "**But what really is Feature Engineering?**\n",
    "\n",
    "I believe that the best way to understand something new is simply by doing it. <br>For further readings you can see references or find some very good material online.\n",
    "\n",
    "<img src='files/the-3-secrets-of-highly-successful-graduates-78-638.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attribute = Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### Print all names in column 'Name'\n",
    "### Write your code here\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### With every name of passenger you would find an extra title i.e Mr., Mrs., Miss. and e.t.c.\n",
    "### Go ahead and take a deeper look at the name of passengers.\n",
    "###\n",
    "### I suspect that this title might be informative\n",
    "### Create a new column with name 'title' and store the title of each passenger\n",
    "### You might have to write a regular expression for extracting title from names.\n",
    "###\n",
    "### Write your code here\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### Some of the titles might be very rare i.e only 1 or 2 passengers\n",
    "### Group all such variables into one category 'Rare' and print all the unique entries in the column 'Title'\n",
    "### Now the title attribute would have categories like Mr, Miss, Rare\n",
    "###\n",
    "### Write your code here\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### Finally drop the 'Name' column from dataframe\n",
    "### Write your code here\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Members of family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### SibSp represents # of siblings/spouses aboard the ship\n",
    "### Parch represents # of parents/children aboard the titanic\n",
    "###\n",
    "### If we add these two variables we can get the family size of each passenger.\n",
    "### Create a new variable called 'Members' by adding SibSp and Parch for each passenger\n",
    "### \n",
    "### Write your code here\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### \n",
    "### If the count add up to zero it means the person is travelling alone else not.\n",
    "### Create a new boolean column called 'Alone'\n",
    "### It would be 1 if the passenger is travelling alone else 0.\n",
    "###\n",
    "### Write your code here\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### In the first Homework you might have replaced missing values with mean of column.\n",
    "### It is absolutely fine to use the mean. \n",
    "### However, an alternative approach could be to replace using grouping.\n",
    "### For example, we would group all males and females and take their mean separately\n",
    "### Now we would check that if the passenger is male we would replace it's missing age with male's mean and vice versa.\n",
    "###\n",
    "### Implement the above strategy for replacing missing age values\n",
    "###\n",
    "### Write your code here\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Has Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### Check total null values in the column 'Cabin'\n",
    "### You might notice that it has a lot of null values.\n",
    "### A natural choice would be to immediately drop this variable.\n",
    "### However, this variable might help us differentiate among passengers having cabin or not.\n",
    "###\n",
    "### Create a new boolean column called 'has_cabin' \n",
    "### It would be 1 if there is some value in cabin else it would be zero\n",
    "### i.e. if there is no cabin then we would put a '0' in has_cabin column\n",
    "###\n",
    "### Write your code here\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### Remove the column 'Cabin'\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probably now you would have more features then before. Feature Engineering is an art, coming up with meaningful features is a big skill and comes by domain knowledge and practice.\n",
    "* You are free to play around and come up with your own features such that they are also useful in prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing on Numeric Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformations\n",
    "\n",
    "A variable transformation refers to a transformation that is applied to all the values of a variable. For example, if only the magnitude of a variable is important, then the values of the variable can be transformed by taking the absolute value. If $x$ is a variable, then examples of such transformations include $x^k$, $log(x)$, $e^x$, $\\sqrt{x}$ and others.\n",
    "\n",
    "\n",
    "#### Standardization\n",
    "\n",
    "The result of standardization (or Z-score normalization) is that the features will be rescaled so that they’ll have the properties of a standard normal distribution with $\\mu = 0$ and $\\sigma = 1$, where $\\mu$ is the mean (average) and $\\sigma$ is the standard deviation;\n",
    "\n",
    "Standard scores (also called z scores) of the samples are calculated as follows:\n",
    "\n",
    "$$z = \\frac{x-\\mu}{\\sigma}$$\n",
    "\n",
    "Standardizing the features so that they are centered around 0 with a standard deviation of 1 is not only important if we are comparing measurements that have different units, but it is also a general requirement for many machine learning algorithms. Intuitively, we can think of gradient descent as a prominent example (an optimization algorithm often used in logistic regression, SVMs, perceptrons, neural networks etc.); with features being on different scales, certain weights may update faster than others since the feature values $x_j$ play a role in the weight updates.\n",
    "\n",
    "#### Normalization\n",
    "\n",
    "An alternative approach to Z-score normalization (or standardization) is the so-called Min-Max scaling (often also simply called “Min Max Normalization”).\n",
    "In this approach, the data is scaled to a fixed range - usually 0 to 1.\n",
    "\n",
    "A Min-Max scaling is typically done via the following equation:\n",
    "\n",
    "$$ X_{norm} = \\frac{X - X_{min}}{X_{max} - X_{min}}$$\n",
    "\n",
    "#### Discretization\n",
    "\n",
    "Discretization(binning) is an unsupervised method that transforms numerical variable into categorical counterparts but do not use the target (class) information. Equal Width and Equal Frequency are two unsupervised binning methods.\n",
    "\n",
    " \t\t\n",
    "##### 1- Equal Width Binning\n",
    "The algorithm divides the data into $k$ intervals of equal size. The width of intervals is:\t\t\n",
    "$$ w = \\frac{max-min}{k}$$\n",
    "\n",
    "And the interval boundaries are:\t\n",
    "\n",
    "$$ min+w, min+2w, ... , min+(k-1)w $$\n",
    "\n",
    "##### 2- Equal Frequency Binning\n",
    "The algorithm divides the data into $k$ groups which each group contains approximately same number of values. For the both methods, the best way of determining $k$ is by looking at the histogram and try different intervals or groups.\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gaussian_transform( data ):\n",
    "    \"\"\"\n",
    "    There are some special transformations that convert a Non-Gaussian Distribution to Gaussian Distribution.\n",
    "    Implement the function gaussian_transform that takes as input a numeric array and converts it to gaussian.\n",
    "    Do not use any built-in library. You have to implement this function yourself.\n",
    "    \"\"\"\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def standardize( data ):\n",
    "    \"\"\"\n",
    "    Implement the function standardize that takes as input a numeric array and returns it's standardize version.\n",
    "    Do not use any built-in library. You have to implement this function yourself.\n",
    "    \"\"\"\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize( data ):\n",
    "    \"\"\"\n",
    "    Implement the function normalize that takes as input a numeric array and returns it's normalized version.\n",
    "    Do not use any built-in library. You have to implement this function yourself.\n",
    "    \"\"\"\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discretize( data, method, k ):\n",
    "    \"\"\"\n",
    "    Implement the function discretize that takes as input a numeric array and returns it's binned version.\n",
    "    It also takes in an argument \"method\" whose value can be \"equal_width\" or \"equal_freq\". \n",
    "    k represents # of bins that should also be passed by the user\n",
    "    Implement both the variants inside this function.\n",
    "    Do not use any built-in library. You have to implement this function yourself.\n",
    "    \"\"\"\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Test Pre-processing\n",
    "\n",
    "### Use the age variable as input.\n",
    "### Test the functions normalize(), standardize() and discretize()\n",
    "### Display your result in the form of graphs\n",
    "### 1 - plot a graph for original age\n",
    "### 2 - plot a graph for gaussian transformed age\n",
    "### 3 - plot a graph for standardized age\n",
    "### 4 - plot a graph for normalized age\n",
    "### 5 - plot a graph for discretized age with equal_width\n",
    "### 6 - plot a graph for discretized age with equal_frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### \n",
    "### Encode your categorical/strings data to numeric format\n",
    "### Do not use any built-in library\n",
    "### Write your code here\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correlation( attribute_1, attribute_2 ):\n",
    "    \"\"\"\n",
    "    Implement the function correlation that takes as input 2 numeric variables and calculates correlation between them.\n",
    "    Use Pearson Correlation - The one which you studied in class\n",
    "    Do not use built in libraries\n",
    "    \"\"\"\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### Calculate correlation between all the attributes and target class\n",
    "### If you have 10 attributes and 1 class\n",
    "### You should have 10 correlation values\n",
    "### Arrange these values, such that attributes with high correlation come at top\n",
    "### Write your code here\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Trees (DTs) are a non-parametric supervised learning method used for classification. The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features.\n",
    "\n",
    "Advantages: \n",
    "    \n",
    "* Decision Trees are very flexible, and expressive classifiers.\n",
    "* They can accommodate any kind of data i.e numeric, categorical and e.t.c.\n",
    "* They can accommodate any number of classes,they are inherently multi-class\n",
    "* Most importantly, they are **extremely interpretable**\n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "* Prone to over-fitting\n",
    "\n",
    "Last time we built a decision tree and saw some of it's advantages. This time we will dig deep further into decision trees, there disadvantages and how to handle them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### Before you train your model, split the data in training and testing set. \n",
    "### You are not to use any built-in library. \n",
    "### Keep approximately 80:20 train:test split ratio\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### Using sklearn\n",
    "### Train a simple decision Tree Classifier on training data\n",
    "### Use default settings and do not change any parameters of the module\n",
    "### \n",
    "### Write your code here\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### Report your accuracy for training set and testing set both\n",
    "### i.e. \n",
    "### Training Accuracy = ???\n",
    "### Testing Accuracy = ???\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question)** Did feature engineering improve accuracy of your model? You can compare your results from last notebook. Report your results.\n",
    "\n",
    "Please write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Over-fitting\n",
    "\n",
    "Over-fitting and under-fitting are common problems you would encounter in the world of machine learning.\n",
    "\n",
    "<img src='files/overfitting.png'>\n",
    "\n",
    "I hope you have studied over-fitting in class and would have explored yourself as well. Just to give you intuition:\n",
    "\n",
    "* Under-fitting is when you do not try at all to classify data properly.\n",
    "* Optimum solution is what you are looking for.\n",
    "* Over-fitting is when you try too hard to classify the data.\n",
    "\n",
    "<img src='files/CRZGo.png'>\n",
    "\n",
    "Not to worry if you still have issues understanding over-fitting. This concept would be popping up from time to time.<br>\n",
    "So, let's end theoretical discussion and see over-fitting in action on decision trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criterion Parameter For Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### In the DecisionTreeClassifier() module there is a paramter called criterion - gini/entropy\n",
    "### We will alter this parameter to see how training and testing accuracy varies.\n",
    "### Leave rest of the parameters to default\n",
    "### \n",
    "### Train separately two decision tree classifiers on gini and entropy.\n",
    "### \n",
    "### For each Classifier report training and testing accuracy.\n",
    "###\n",
    "### Write your code here\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### \n",
    "### Compare the results of using different criterion\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Max Leaf Nodes Parameter in Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### In the DecisionTreeClassifier() module there is a paramter called max_leaf_nodes\n",
    "### We will alter this parameter to see how training and testing accuracy varies.\n",
    "### Leave rest of the parameters to default\n",
    "### \n",
    "### Train several decision tree classifiers on different values of max_leaf_nodes.\n",
    "### Remember the minimum value of max_leaf_nodes is 2 and max is infinity.\n",
    "### You could start from 2, 5, 10, 20, 30, 40 or any order you think is suitable.\n",
    "### \n",
    "### For each Classifier report training and testing accuracy.\n",
    "### Save these values in two separate lists\n",
    "###\n",
    "### Write your code here\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### Finally draw a line plot similar to the Train/Test Performance graph shown above\n",
    "### On x-axis you would have max_leaf_nodes \n",
    "### On y-axis you would have error rate\n",
    "### There would be 2 lines on graph; one for training error and other for testing error\n",
    "### \n",
    "### Write your code here \n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Max Depth Parameter in Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### In the DecisionTreeClassifier() module there is a paramter called max_depth\n",
    "### We will alter this parameter to see how training and testing accuracy varies.\n",
    "### Leave rest of the parameters to default\n",
    "### \n",
    "### Train several decision tree classifiers on different values of max_depth.\n",
    "### You could start from 2, 3, 4, 5, ...  or any order you think is suitable.\n",
    "### \n",
    "### For each Classifier report training and testing accuracy.\n",
    "### Save these values in two separate lists\n",
    "###\n",
    "### Write your code here\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### Finally draw a line plot similar to the Train/Test Performance graph shown above\n",
    "### On x-axis you would have max_depth \n",
    "### On y-axis you would have error rate\n",
    "### There would be 2 lines on graph; one for training error and other for testing error\n",
    "### \n",
    "### Write your code here \n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Max Samples Leaf Parameter in Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### In the DecisionTreeClassifier() module there is a paramter called min_samples_leaf\n",
    "### We will alter this parameter to see how training and testing accuracy varies.\n",
    "### Leave rest of the parameters to default\n",
    "### \n",
    "### Train several decision tree classifiers on different values of min_samples_leaf.\n",
    "### You could start from 2, 5, 10, 20, 30, 40 or any order you think is suitable.\n",
    "### \n",
    "### For each Classifier report training and testing accuracy.\n",
    "### Save these values in two separate lists\n",
    "###\n",
    "### Write your code here\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### Finally draw a line plot similar to the Train/Test Performance graph shown above\n",
    "### On x-axis you would have min_samples_leaf \n",
    "### On y-axis you would have error rate\n",
    "### There would be 2 lines on graph; one for training error and other for testing error\n",
    "### \n",
    "### Write your code here \n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree vs Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above discussion, it is clear that Decision Tree are prone to over-fitting. One way of handling over-fitting is to use **Random Forests.**\n",
    "\n",
    "<img src = \"random_forest.png\">\n",
    "\n",
    "Random forests are an ensemble learning method for classification that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) of the individual trees. Random decision forests correct for decision trees habit of overfitting to their training set.\n",
    "\n",
    "Random forests are a **must know** ensemble classifier for data scientist. You can read more about Ensemble classifiers and Random forests on the internet to get a better understanding of their working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### Using sklearn\n",
    "### Train a random forest classifier on training data\n",
    "### For your own understanding, you can play around by changing the parameters as you did with decision tree.\n",
    "### For this homework, leave the parameters to default.\n",
    "###\n",
    "### Write your code here\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### Report your training and testing accuracy\n",
    "### i.e. \n",
    "### Training Accuracy = ???\n",
    "### Testing Accuracy = ???\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### Plot a graph that clearly shows the testing accuracy comparison of Decision Tree with Random Forest.\n",
    "### It should be properly labeled and intuitive.\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In case of any issues or comments, please provide your feedback here**\n",
    "\n",
    "Please remove me before writing your feedback<br>\n",
    "Hey I am a student of MSDS<br>\n",
    "My name is .....<br>\n",
    "I am writing this feedback because I had these issues ...<br>\n",
    "I think you should make the following changes for upcoming students ...<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "You are on path to a Professional Data Science. **Keep up the Great Work!!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='great-work.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References\n",
    "\n",
    "[1] https://www.emojirequest.com/r/ConfusedEmoji\n",
    "<br>\n",
    "[2] https://medium.com/mindorks/what-is-feature-engineering-for-machine-learning-d8ba3158d97a\n",
    "<br>\n",
    "[3] https://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/\n",
    "<br>\n",
    "[4] https://towardsdatascience.com/understanding-feature-engineering-part-1-continuous-numeric-data-da4e47099a7b\n",
    "<br>\n",
    "[5] https://en.wikipedia.org/wiki/Feature_engineering\n",
    "<br>\n",
    "[6] https://www.slideshare.net/reidhoffman/the-3-secrets-of-highly-successful-graduates/78-Learn_by_DOING\n",
    "<br>\n",
    "[7] https://stats.stackexchange.com/questions/160902/is-it-possible-for-test-error-to-be-lower-than-training-error\n",
    "<br>\n",
    "[8] https://medium.com/@srjoglekar246/overfitting-and-human-behavior-5186df1e7d19\n",
    "<br>\n",
    "[9] http://www.thedrive.com/vintage/3063/watch-this-virtual-titanic-sink-in-real-time\n",
    "<br>\n",
    "[10] http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "<br>\n",
    "[11] https://en.wikipedia.org/wiki/Pearson_correlation_coefficient\n",
    "<br>\n",
    "[12] https://www.sharelatex.com/learn/latex/Subscripts_and_superscripts\n",
    "<br>\n",
    "[13] https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Working%20With%20Markdown%20Cells.html\n",
    "<br>\n",
    "[14] https://sebastianraschka.com/Articles/2014_about_feature_scaling.html\n",
    "<br>\n",
    "[15] http://www.saedsayad.com/unsupervised_binning.htm\n",
    "<br>\n",
    "[16] https://en.wikipedia.org/wiki/Discretization_of_continuous_features\n",
    "<br>\n",
    "[17] https://en.wikipedia.org/wiki/Normalization_(statistics)\n",
    "<br>\n",
    "[18] Tan, Pang-Ning. Introduction to data mining. Pearson Education India, 2006.\n",
    "<br>\n",
    "[19] T. Hastie, R. Tibshirani and J. Friedman. Elements of Statistical Learning, Springer, 2009.\n",
    "<br>\n",
    "[20] http://scikit-learn.org/stable/modules/tree.html\n",
    "<br>\n",
    "[21] J.R. Quinlan. C4. 5: programs for machine learning. Morgan Kaufmann, 1993.\n",
    "<br>\n",
    "[22] L. Breiman, J. Friedman, R. Olshen, and C. Stone. Classification and Regression Trees. Wadsworth, Belmont, CA, 1984.\n",
    "<br>\n",
    "[23] https://medium.com/@williamkoehrsen/random-forest-simple-explanation-377895a60d2d\n",
    "<br>\n",
    "[24] https://en.wikipedia.org/wiki/Random_forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This notebook has been prepared by:<br><br>\n",
    "**Faizan Saeed**<br>\n",
    "**Graduate Fellow**<br>\n",
    "**Data Science Lab**<br><br>\n",
    "In case of any issue, please e-mail at: **MSDS17005@ITU.EDU.PK**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
